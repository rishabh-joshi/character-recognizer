{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Modeling on the EMNIST dataset\n",
    "\n",
    "We are trying to create a good neural network model for the EMNIST dataset which contains 28x28 sized grayscale pixel images of the digits 0-9, and the letters a-z and A-Z. I will train and test my neural network on two versions of the dataset. \n",
    "\n",
    "## Description of the dataset\n",
    "\n",
    "The balanced EMNIST dataset contains 112,800 training samples and 18,800 test samples. The byclass EMNIST dataset contains 697,932 training samples and 116,323 test samples. \n",
    "\n",
    "The balanced dataset contains equall proportion of all classes in the training and testing data but only contains 47 clases. This is because some of the letter classes are merged together. For example, 'o' and 'O' are very hard to distinguish between.\n",
    "\n",
    "The byclass dataset cotains 62 classes with all the possible characters in a class of their own. Since, this dataset has 6 times more data than the balanced dataset, we might end up choosing this one over the balanced dataset.\n",
    "\n",
    "## Loading required libraries\n",
    "\n",
    "I will use the Keras library to build neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "Reading the balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0   41    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1   39    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    9    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3   26    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4   44    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../data/emnist-balanced-train.csv\", header = None)\n",
    "test_data = pd.read_csv(\"../data/emnist-balanced-test.csv\", header = None)\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 785)\n",
      "(18800, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the response from the predictor variables in the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41\n",
       "1    39\n",
       "2     9\n",
       "3    26\n",
       "4    44\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_data[0]\n",
    "train_y.head()\n",
    "test_y = test_data[0]\n",
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1    2    3    4    5    6    7    8    9    10  ...   775  776  777  778  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_data.iloc[:, 1:]\n",
    "train_X.head()\n",
    "test_X = test_data.iloc[:, 1:]\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a simple neural network model\n",
    "\n",
    "Creating a very simple neural network model with one hidden layer, training, and testing it on the data to see the performance and set up a baseline to improve upon with more complex neural nets later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 784)\n",
      "(112800, 784) (112800,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "\n",
    "# use full dataset\n",
    "Xtr = train_X\n",
    "Ytr = train_y\n",
    "print(Xtr.shape, Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the structure of the neural network\n",
    "\n",
    "Defining the structure of the neural net: the size of the input layer, one hidden layer and the size of that layer, the method used for optimizing, the metric and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 47 classes (categorical classification):\n",
    "num_classes = 47 # number of classes present in the data\n",
    "inp_dim = train_X.shape[1]\n",
    "model_simple = Sequential()\n",
    "model_simple.add(Dense(32, activation='relu', input_dim=inp_dim)) # First hidden layer\n",
    "model_simple.add(Dense(num_classes, activation='softmax')) # output layer\n",
    "model_simple.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert the response to one-hot encoding\n",
    "one_hot_labels = to_categorical(Ytr, num_classes=num_classes)\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Fit the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112800/112800 [==============================] - 9s 84us/step - loss: 14.1056 - acc: 0.1224\n",
      "Epoch 2/10\n",
      "112800/112800 [==============================] - 10s 87us/step - loss: 13.7326 - acc: 0.1467\n",
      "Epoch 3/10\n",
      "112800/112800 [==============================] - 11s 95us/step - loss: 13.6862 - acc: 0.1498\n",
      "Epoch 4/10\n",
      "112800/112800 [==============================] - 9s 79us/step - loss: 13.6472 - acc: 0.1523\n",
      "Epoch 5/10\n",
      "112800/112800 [==============================] - 10s 91us/step - loss: 13.6237 - acc: 0.1539\n",
      "Epoch 6/10\n",
      "112800/112800 [==============================] - 11s 99us/step - loss: 13.6031 - acc: 0.1552\n",
      "Epoch 7/10\n",
      "112800/112800 [==============================] - 11s 93us/step - loss: 13.5956 - acc: 0.1558\n",
      "Epoch 8/10\n",
      "112800/112800 [==============================] - 10s 87us/step - loss: 13.5818 - acc: 0.1567\n",
      "Epoch 9/10\n",
      "112800/112800 [==============================] - 10s 89us/step - loss: 13.5743 - acc: 0.1571\n",
      "Epoch 10/10\n",
      "112800/112800 [==============================] - 10s 86us/step - loss: 13.5667 - acc: 0.1576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff53a509470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "model_simple.fit(Xtr.values, one_hot_labels, epochs=epochs, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model performance on training data\n",
    "\n",
    "Testing the performance of the model in the training data and looking at the training accuracy of the model using a confusion matrix. To predict the class using the neural net, we can use the predict_classes function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0    0]\n",
      " [   1 2311   64 ...   41   72  808]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    1    1 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n",
      "accuracy on training data = 0.15843971631205675\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on the training data\n",
    "pred = model_simple.predict_classes(Xtr.values)\n",
    "\n",
    "# taking the maximum output as the predicted class label and then building the confusion matrix\n",
    "cmat = confusion_matrix(pred, Ytr.values)\n",
    "print(cmat)\n",
    "print(\"accuracy on training data =\", cmat.diagonal().sum()/cmat.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the training data for the simple neural network model is 15.84%. We should be able to do a lot better by having a more complex neural network model and later through convolutional neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and reloading the model\n",
    "\n",
    "Keras offers the functionality to save the trained neural network model to disk so that once trained, the same model can be used again for prediction without any need to refit. If later we get more data, we can even continue training the saved neural network model on the new data using the current values of the weights as starting points. Saving the model to disk as an HDF5 file to be able to reload it later in the web application at the time of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_simple.save('../models/model_simple.h5')  # creates a HDF5 file 'model_simple.h5'\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model_simple2 = load_model('../models/model_simple.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more nodes in the hidden layer and including a dropout rate\n",
    "\n",
    "Increasing the number of nodes in the hidden layer to make the model more complex and checking the performance of this new model. I have also included a drop out rate of 0.2 to avoid overfitting since I have increased the number of nodes in the hidden layer to 1024 from 32 previously. Dropout of 0.2 means that at the time of training, 20% of the nodes will be removed at random from the hidden layer for each pass of the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 47 classes (categorical classification):\n",
    "num_classes = 47 # number of classes present in the data\n",
    "inp_dim = train_X.shape[1]\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Dense(1024, activation='relu', input_dim=inp_dim)) # First hidden layer\n",
    "model_dropout.add(Dropout(0.2))\n",
    "model_dropout.add(Dense(num_classes, activation='softmax')) # output layer\n",
    "model_dropout.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert the response to one-hot encoding\n",
    "one_hot_labels = to_categorical(Ytr, num_classes=num_classes)\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab.analytics.northwestern.edu/rjoshi/.local/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 101520 samples, validate on 11280 samples\n",
      "Epoch 1/10\n",
      "101520/101520 [==============================] - 25s 244us/step - loss: 15.7544 - acc: 0.0225 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 2/10\n",
      "101520/101520 [==============================] - 28s 275us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 3/10\n",
      "101520/101520 [==============================] - 47s 460us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 4/10\n",
      "101520/101520 [==============================] - 45s 441us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 5/10\n",
      "101520/101520 [==============================] - 42s 410us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 6/10\n",
      "101520/101520 [==============================] - 43s 420us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 7/10\n",
      "101520/101520 [==============================] - 41s 400us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 8/10\n",
      "101520/101520 [==============================] - 45s 443us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 9/10\n",
      "101520/101520 [==============================] - 43s 419us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n",
      "Epoch 10/10\n",
      "101520/101520 [==============================] - 45s 443us/step - loss: 15.7764 - acc: 0.0212 - val_loss: 15.7637 - val_acc: 0.0220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f4451320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.fit(Xtr.values, one_hot_labels, # Train the model using the training set...\n",
    "          batch_size=batch_size, nb_epoch=epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "accuracy on training data = 0.02127659574468085\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on the training data\n",
    "pred_dropout = model_dropout.predict_classes(Xtr.values)\n",
    "\n",
    "# taking the maximum output as the predicted class label and then building the confusion matrix\n",
    "cmat = confusion_matrix(pred_dropout, Ytr.values)\n",
    "print(cmat)\n",
    "print(\"accuracy on training data =\", cmat.diagonal().sum()/cmat.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the performance of simple neural networks is very poor when it comes to the accuracy of the model on the training set. Since the training accuracy itself is very low, we can conclude that the performance on the test set would also not be very good. Therefore, to increase the accuracy and hence, the performance of the model on the train as well as test data, we move on to convolutional neural networks in the next notebook."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
